{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# add the 'src' directory as one where we can import modules\n",
    "# os.pardir refers to parent directory. \n",
    "# src_dir = os.path.join(os.getcwd(), '../src') => works the same\n",
    "src_dir = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# Load the \"autoreload\" extension\n",
    "%load_ext autoreload\n",
    "# always reload modules marked with \"%aimport\"\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End loading training data (463 docs) in 0.03 sec\n",
      "Transforming list of documents to sparse matrix\n",
      "X (sparse matrix) shape: (463, 14485)\n",
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n",
      "28 operators have been imported by TPOT.\n",
      "X_train shape: (347, 14485)\n",
      "X_test shape: (116, 14485)\n",
      "Start of fitting model\n",
      "_pre_test decorator: _generate: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "_pre_test decorator: _generate: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "_pre_test decorator: _generate: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "_pre_test decorator: _generate: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances.\n",
      "_pre_test decorator: _generate: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "_pre_test decorator: _generate: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "_pre_test decorator: _generate: num_test=1 Input X must be non-negative\n",
      "_pre_test decorator: _generate: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "_pre_test decorator: _generate: num_test=0 Input X must be non-negative\n",
      "_pre_test decorator: _generate: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required.\n",
      "_pre_test decorator: _generate: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "_pre_test decorator: _generate: num_test=0 Input X must be non-negative\n",
      "_pre_test decorator: _generate: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "_pre_test decorator: _generate: num_test=0 Input X must be non-negative\n",
      "_pre_test decorator: _generate: num_test=0 Input X must be non-negative"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Optimization Progress:   0%|          | 0/10100 [00:00<?, ?pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_pre_test decorator: _generate: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "_pre_test decorator: _generate: num_test=0 Input X must be non-negative\n",
      "_pre_test decorator: _generate: num_test=0 Input X must be non-negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:   0%|          | 13/10100 [03:37<40:48:40, 14.57s/pipeline]"
     ]
    }
   ],
   "source": [
    "%run ../src/models/tpot_maker.py --data ../data/train/emotion-large.2-label.tsv.gz --script ../models/tpot_pipeline_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = load_digits()\n",
    "type(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  32%|███▏      | 97/300 [00:27<00:41,  4.94pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.9739130434782609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  47%|████▋     | 142/300 [00:51<00:51,  3.09pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.9739130434782609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  63%|██████▎   | 190/300 [01:15<00:43,  2.52pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 0.9739130434782609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  79%|███████▉  | 237/300 [01:32<00:13,  4.83pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: 0.9739130434782609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 5 - Current best internal CV score: 0.9739130434782609\n",
      "\n",
      "Best pipeline: GaussianNB(Normalizer(input_matrix, Normalizer__norm=l1))\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data.astype(np.float64),\n",
    "    iris.target.astype(np.float64), train_size=0.75, test_size=0.25)\n",
    "\n",
    "tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))\n",
    "tpot.export('tpot_iris_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 5.2,  4.1,  1.5,  0.1],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 6. ,  3.4,  4.5,  1.6],\n",
       "       [ 6.7,  3.1,  4.7,  1.5],\n",
       "       [ 5.4,  3.9,  1.3,  0.4],\n",
       "       [ 5.4,  3.7,  1.5,  0.2],\n",
       "       [ 5.5,  2.4,  3.7,  1. ],\n",
       "       [ 6.3,  2.8,  5.1,  1.5],\n",
       "       [ 6.4,  3.1,  5.5,  1.8],\n",
       "       [ 6.6,  3. ,  4.4,  1.4],\n",
       "       [ 7.2,  3.6,  6.1,  2.5],\n",
       "       [ 5.7,  2.9,  4.2,  1.3],\n",
       "       [ 7.6,  3. ,  6.6,  2.1],\n",
       "       [ 5.6,  3. ,  4.5,  1.5],\n",
       "       [ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 7.7,  2.8,  6.7,  2. ],\n",
       "       [ 5.8,  2.7,  4.1,  1. ],\n",
       "       [ 5.2,  3.4,  1.4,  0.2],\n",
       "       [ 5. ,  3.5,  1.3,  0.3],\n",
       "       [ 5.1,  3.8,  1.9,  0.4],\n",
       "       [ 5. ,  2. ,  3.5,  1. ],\n",
       "       [ 6.3,  2.7,  4.9,  1.8],\n",
       "       [ 4.8,  3.4,  1.9,  0.2],\n",
       "       [ 5. ,  3. ,  1.6,  0.2],\n",
       "       [ 5.1,  3.3,  1.7,  0.5],\n",
       "       [ 5.6,  2.7,  4.2,  1.3],\n",
       "       [ 5.1,  3.4,  1.5,  0.2],\n",
       "       [ 5.7,  3. ,  4.2,  1.2],\n",
       "       [ 7.7,  3.8,  6.7,  2.2],\n",
       "       [ 4.6,  3.2,  1.4,  0.2],\n",
       "       [ 6.2,  2.9,  4.3,  1.3],\n",
       "       [ 5.7,  2.5,  5. ,  2. ],\n",
       "       [ 5.5,  4.2,  1.4,  0.2],\n",
       "       [ 6. ,  3. ,  4.8,  1.8],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 6. ,  2.2,  4. ,  1. ],\n",
       "       [ 5.4,  3. ,  4.5,  1.5],\n",
       "       [ 6.2,  3.4,  5.4,  2.3],\n",
       "       [ 5.5,  2.3,  4. ,  1.3],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 5. ,  2.3,  3.3,  1. ],\n",
       "       [ 6.4,  2.7,  5.3,  1.9],\n",
       "       [ 5. ,  3.3,  1.4,  0.2],\n",
       "       [ 5. ,  3.2,  1.2,  0.2],\n",
       "       [ 5.5,  2.4,  3.8,  1.1],\n",
       "       [ 6.7,  3. ,  5. ,  1.7],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5.8,  2.8,  5.1,  2.4],\n",
       "       [ 5. ,  3.4,  1.5,  0.2],\n",
       "       [ 5. ,  3.5,  1.6,  0.6],\n",
       "       [ 5.9,  3.2,  4.8,  1.8],\n",
       "       [ 5.1,  2.5,  3. ,  1.1],\n",
       "       [ 6.9,  3.2,  5.7,  2.3],\n",
       "       [ 6. ,  2.7,  5.1,  1.6],\n",
       "       [ 6.1,  2.6,  5.6,  1.4],\n",
       "       [ 7.7,  3. ,  6.1,  2.3],\n",
       "       [ 5.5,  2.5,  4. ,  1.3],\n",
       "       [ 4.4,  2.9,  1.4,  0.2],\n",
       "       [ 4.3,  3. ,  1.1,  0.1],\n",
       "       [ 6. ,  2.2,  5. ,  1.5],\n",
       "       [ 7.2,  3.2,  6. ,  1.8],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5.1,  3.5,  1.4,  0.3],\n",
       "       [ 4.4,  3. ,  1.3,  0.2],\n",
       "       [ 6.3,  2.5,  4.9,  1.5],\n",
       "       [ 6.3,  3.4,  5.6,  2.4],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 6.8,  3. ,  5.5,  2.1],\n",
       "       [ 6.3,  3.3,  6. ,  2.5],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 6.1,  2.9,  4.7,  1.4],\n",
       "       [ 6.5,  2.8,  4.6,  1.5],\n",
       "       [ 6.2,  2.8,  4.8,  1.8],\n",
       "       [ 7. ,  3.2,  4.7,  1.4],\n",
       "       [ 6.4,  3.2,  5.3,  2.3],\n",
       "       [ 5.1,  3.8,  1.6,  0.2],\n",
       "       [ 6.9,  3.1,  5.4,  2.1],\n",
       "       [ 5.9,  3. ,  4.2,  1.5],\n",
       "       [ 6.5,  3. ,  5.2,  2. ],\n",
       "       [ 5.7,  2.6,  3.5,  1. ],\n",
       "       [ 5.2,  2.7,  3.9,  1.4],\n",
       "       [ 6.1,  3. ,  4.6,  1.4],\n",
       "       [ 4.5,  2.3,  1.3,  0.3],\n",
       "       [ 6.6,  2.9,  4.6,  1.3],\n",
       "       [ 5.5,  2.6,  4.4,  1.2],\n",
       "       [ 5.3,  3.7,  1.5,  0.2],\n",
       "       [ 5.6,  3. ,  4.1,  1.3],\n",
       "       [ 7.3,  2.9,  6.3,  1.8],\n",
       "       [ 6.7,  3.3,  5.7,  2.1],\n",
       "       [ 5.1,  3.7,  1.5,  0.4],\n",
       "       [ 4.9,  2.4,  3.3,  1. ],\n",
       "       [ 6.7,  3.3,  5.7,  2.5],\n",
       "       [ 7.2,  3. ,  5.8,  1.6],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 6.7,  3.1,  5.6,  2.4],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 6.9,  3.1,  4.9,  1.5],\n",
       "       [ 7.4,  2.8,  6.1,  1.9],\n",
       "       [ 6.3,  2.9,  5.6,  1.8],\n",
       "       [ 5.7,  2.8,  4.1,  1.3],\n",
       "       [ 6.5,  3. ,  5.5,  1.8],\n",
       "       [ 6.3,  2.3,  4.4,  1.3],\n",
       "       [ 6.4,  2.9,  4.3,  1.3],\n",
       "       [ 5.6,  2.8,  4.9,  2. ],\n",
       "       [ 5.9,  3. ,  5.1,  1.8],\n",
       "       [ 5.4,  3.4,  1.7,  0.2],\n",
       "       [ 6.1,  2.8,  4. ,  1.3],\n",
       "       [ 4.9,  2.5,  4.5,  1.7],\n",
       "       [ 5.8,  4. ,  1.2,  0.2],\n",
       "       [ 5.8,  2.6,  4. ,  1.2],\n",
       "       [ 7.1,  3. ,  5.9,  2.1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
