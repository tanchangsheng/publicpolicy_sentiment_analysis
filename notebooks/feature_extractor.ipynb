{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Load the \"autoreload\" extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# always reload modules marked with \"%aimport\"\n",
    "%autoreload 1\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# add the 'src' directory as one where we can import modules\n",
    "# os.pardir refers to parent directory. \n",
    "# src_dir = os.path.join(os.getcwd(), '../src') => works the same\n",
    "src_dir = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# import my method from the source code\n",
    "# %aimport auto reloads the imported modules.\n",
    "# e.g. if i make changes to features.build_features and make edits to the source code,\n",
    "# autoreload reloads modules automatically before entering the execution of code typed at the IPython prompt.\n",
    "%aimport features.test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/Users/changsheng/Dropbox/LARC/Project/publicpolicy_sentimentanalysis/src/features/features_extractor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcmd_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'car'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "%run ../src/features/features_extractor.py --data '{\"car\":\"toyota\",\"dog\":\"twinkle\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hellohello\n"
     ]
    }
   ],
   "source": [
    "pt('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/changsheng/Dropbox/LARC/Project/publicpolicy_sentimentanalysis/notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "%run ../src/features/features_extractor.py hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " h To be Reach Lee at           PAP    C                                                         C KX\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['to', 'be', 'reach', 'lee', 'at', 'pap', 'kx']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "import unicodedata\n",
    "# import codecs\n",
    "text = ' h@hello hsleewrote To: 123123 4be Reach \\/ \\n\\n 1 am 4PM Lee at 3pm\\n\\u6211\\u8981\\u5411\\u9648\\u632F\\u58F0\\u5927\\u90E8\\u957F\\u53D1\\u51FA\\u6700\\u4E25\\u5389\\u7684\\u8B66\\u544A, \\u8BF7\\u4E0D\\u8981\\u5728\\u4E00\\u77AC\\u95F4\\u7834\\u574F\\u65B0\\u52A0\\u5761\\u7684\\u79CD\\u65CF\\u548C\\u8C10\\u6C1B\\u56F4, \\u8BF7\\u4E0D\\u8981\\u5E26\\u5934\\u6311\\u8D77\\u79CD\\u65CF\\u4E3B\\u4E49, \\u8FD9\\u662F\\u5F88\\u5371\\u9669\\u7684! \\u4F55\\u8C13\\u6C11\\u4E3B?\\u4F55\\u8C13\\u6C11\\u9009? \\u4F55\\u8C13\\u4EFB\\u4EBA\\u552F\\u8D24? \\u9009\\u603B\\u7EDF\\u4E0D\\u662F\\u9009\\u4ED6\\u7684\\u80FD\\u529B\\u5417? \\u800C\\u662F\\u9009\\u80A4\\u8272? \\u8FD9\\u662F\\u54EA\\u95E8\\u7684\\u903B\\u8F91? \\u662FPAP\\u72EC\\u6709\\u7684\\u903B\\u8F91\\u5417? \\n\\u6211\\u65E0\\u6CD5\\u8BA4\\u540C\\u8FD9\\u79CD \\\"\\u6B64\\u5730\\u65E0\\u94F6\\u4E09\\u767E\\u4E24\\\" \\u7684\\u8C2C\\u8BBA !\\n\\u3002\\u3002\\u3002\\u3002\\u3002\\u3002\\u3002\\u3002\\u3002\\u3002\\u3002\\u3002\\u3002\\nCH8: \\u9488\\u5BF9\\u6C11\\u9009\\u603B\\u7EDF\\u5236\\u5EA6\\u7684\\u8BFE\\u9898\\uFF0C\\u603B\\u7406\\u516C\\u7F72\\u90E8\\u957F\\u9648\\u632F\\u58F0\\u8BA4\\u4E3A\\uFF0C\\u4FEE\\u6539\\u6C11\\u9009\\u603B\\u7EDF\\u5236\\u5EA6\\uFF0C\\u662F\\u4E3A\\u4E86\\u786E\\u4FDD\\u6BCF\\u9694\\u4E8C\\u3001\\u4E09\\u5341\\u5E74\\uFF0C\\u81F3\\u5C11\\u6709\\u4F4D\\u5C11\\u6570\\u65CF\\u7FA4\\u5019\\u9009\\u4EBA\\u4EE3\\u8868\\u5F53\\u9009\\u603B\\u7EDF\\u3002\\n\\n\\u9648\\u632F\\u58F0\\u5728\\u56FD\\u5E86\\u7FA4\\u4F17\\u5927\\u4F1A\\u300A\\u751F\\u6D3B.\\u5C31\\u4E1A.\\u8BDD\\u672A\\u6765\\u300B\\u8BBA\\u575B\\u8282\\u76EE\\u4E0A\\uFF0C\\u8C08\\u5230\\u6C11\\u9009\\u603B\\u7EDF\\u7684\\u8BFE\\u9898\\u3002\\n\\n\\u4ED6\\u8BF4\\u65B0\\u52A0\\u5761\\u662F\\u4E00\\u4E2A\\u591A\\u5143\\u79CD\\u65CF\\u7684\\u56FD\\u5BB6\\uFF0C\\u65B0\\u52A0\\u5761\\u7684\\u603B\\u7EDF\\u4E5F\\u5E94\\u8BE5\\u53CD\\u6620\\u8FD9\\u4E00\\u70B9\\u3002\\u653F\\u5E9C\\u672A\\u96E8\\u7EF8\\u7F2A\\uFF0C\\u4EE5\\u514D\\u51E0\\u5341\\u5E74\\u540E\\u51FA\\u73B0\\u6CA1\\u6709\\u5C11\\u6570\\u6C11\\u65CF\\u603B\\u7EDF\\u7684\\u95EE\\u9898\\u3002\\n\\n\\u603B\\u7406\\u516C\\u7F72\\u90E8\\u957F\\u9648\\u632F\\u58F0\\u8BF4\\uFF1A\\u201C\\u771F\\u7684\\u662F\\u5728\\u8FC7\\u4E8C\\u4E09\\u5341\\u5E74\\u6CA1\\u6709\\u4E00\\u4E2A\\u9A6C\\u6765\\u540C\\u80DE\\u5F53\\u9009\\u4E3A\\u6211\\u4EEC\\u7684\\u603B\\u7EDF\\u7684\\u8BDD\\uFF0C\\u5230\\u65F6\\u5019\\u8FD9\\u4E2A\\u95EE\\u9898\\u53EF\\u80FD\\u5C31\\u88AB\\u653F\\u6CBB\\u5316\\uFF0C\\u9A6C\\u6765\\u65CF\\u4ED6\\u4E5F\\u4E0D\\u597D\\u610F\\u601D\\u7AD9\\u51FA\\u6765\\u8BB2\\uFF0C\\u90A3\\u534E\\u65CF\\u5982\\u679C\\u4F60\\u5230\\u4E86\\u90A3\\u65F6\\u5019\\u624D\\u628A\\u8FD9\\u4E2A\\u7CFB\\u7EDF\\u53BB\\u6539\\u53D8\\u7684\\u8BDD\\uFF0C\\u90A3\\u4F60\\u4E5F\\u53EF\\u80FD\\u8BA9\\u4EBA\\u89C9\\u5F97\\u4E00\\u4E2A\\u5370\\u8C61\\u8BF4\\uFF0C\\u4F60\\u592A\\u523B\\u610F\\u7684\\u53BB\\u505A\\u90A3\\u79CD\\u4E1C\\u897F\\u3002\\u6240\\u4EE5\\u6709\\u5F88\\u591A\\u4E8B\\u60C5\\u6211\\u4EEC\\u90FD\\u5F97\\u672A\\u96E8\\u7EF8\\u7F2A\\u3002\\u201D\\n\\n\\u4E0D\\u8FC7\\u4ED6\\u4E5F\\u5F3A\\u8C03\\uFF0C\\u8FD9\\u4E2A\\u673A\\u5236\\u4E0D\\u4F1A\\u56E0\\u4E3A\\u4E00\\u4E24\\u5C4A\\u5185\\u6CA1\\u6709\\u5C11\\u6570\\u6C11\\u65CF\\u603B\\u7EDF\\u800C\\u542F\\u52A8\\u3002\\n\\u56E0\\u4E3A\\u8FD9\\u4E0D\\u662F\\u77ED\\u671F\\u7684\\u673A\\u5236\\u3002\\n\\n\\u5BF9\\u4E8E\\u574A\\u95F4\\u6709\\u4EBA\\u8BA4\\u4E3A\\uFF0C\\u653F\\u5E9C\\u8C03\\u6574\\u6C11\\u9009\\u603B\\u7EDF\\u5236\\u5EA6\\uFF0C\\u662F\\u4E3A\\u4E86\\u963B\\u6B62\\u66FE\\u7ECF\\u7ADE\\u9009\\u603B\\u7EDF\\u7684\\u9648\\u6E05\\u6728\\u533B\\u751F\\u53C2\\u9009\\uFF0C\\u9648\\u632F\\u58F0\\u6307\\u51FA\\uFF0C\\u653F\\u5E9C\\u4E0D\\u53EF\\u80FD\\u4E3A\\u4E86\\u67D0\\u4E00\\u4E2A\\u4EBA\\uFF0C\\u505A\\u51FA\\u90A3\\u4E48\\u5927\\u7684\\u8C03\\u6574\\u3002\\n\\n\\u9648\\u632F\\u58F0\\u8BF4\\uFF1A\\u201C\\u5176\\u5B9E\\u5F88\\u5766\\u767D\\u8BB2\\uFF0C\\u6211\\u4EEC\\u4F5C\\u4E3A\\u4E00\\u4E2A\\u653F\\u5E9C\\uFF0C\\u6211\\u4EEC\\u8981\\u8BBE\\u7ACB\\u4E00\\u4E2A\\u5236\\u5EA6\\u7684\\u65F6\\u5019\\uFF0C\\u90FD\\u8981\\u4EE5\\u56FD\\u5BB6\\u7684\\u4E00\\u4E2A\\u5229\\u76CA\\uFF0C\\u56FD\\u5BB6\\u957F\\u8FDC\\u7684\\u5229\\u76CA\\u6765\\u770B\\u3002\\u5982\\u679C\\u6709\\u4EBA\\u89C9\\u5F97\\u8BF4\\uFF0C\\u6574\\u4E2A\\u5236\\u5EA6\\u662F\\u4E3A\\u4ED6\\u800C\\u8BBE\\u7684\\u8BDD\\uFF0C\\u6211\\u89C9\\u5F97\\u8FD9\\u4E2A\\u4E5F\\u5F88\\u96BE\\u8BB2\\uFF0C\\u6709\\u4E00\\u70B9\\u7275\\u5F3A\\u5566\\u3002\\u201D\\n\\n\\u5F53\\u88AB\\u95EE\\u5230\\u6709\\u5173\\u7B2C\\u56DB\\u4EE3\\u603B\\u7406\\u63A5\\u73ED\\u4EBA\\u7684\\u8BFE\\u9898\\u65F6\\uFF0C\\u9648\\u632F\\u58F0\\u8BA4\\u4E3A\\uFF0C\\u91CD\\u70B9\\u5E94\\u8BE5\\u662F\\u56E2\\u961F,\\u800C\\u4E0D\\u662F\\u4E2A\\u4EBA\\uFF0C\\u56E0\\u6B64,\\u73B0\\u5728\\u6700\\u91CD\\u8981\\u7684\\u4EFB\\u52A1\\uFF0C\\u5C31\\u662F\\u52A0\\u5F3A\\u6574\\u4E2A\\u56E2\\u961F\\u7684\\u5B9E\\u529B\\uFF0C\\u4E0D\\u7BA1\\u78B0\\u5230\\u4EC0\\u4E48\\u72B6\\u51B5\\uFF0C\\u90FD\\u6709\\u8DB3\\u591F\\u80FD\\u529B\\u5E94\\u5BF9\\u3002\\n\\n\\u300A\\u751F\\u6D3B.\\u5C31\\u4E1A.\\u8BDD\\u672A\\u6765\\u300B\\u5728\\u65B0\\u95FB\\u7ED3\\u675F\\u540E\\u64AD\\u51FA\\u3002\\n- CH8\\/KX'\n",
    "# text = text.decode('utf8')\n",
    "# text = unicodedata.normalize('NFD', text).encode('ascii', 'ignore')\n",
    "text = text.replace(r'\\n', ' ')\n",
    "text = text.replace('\\/', '/')\n",
    "# text = re.sub('\\\\\\u[0-9]+[a-zA-Z]*',' ', text) # remove encoded text, e.g., \\u201d\n",
    "\n",
    "\t# for forum posts\n",
    "text = re.sub('\\w+wrote', ' ', text) # remove usernamewrote\n",
    "text = re.sub('gagt\\w*', ' ', text) # remove gagt*\n",
    "text = re.sub('[a-zA-Z][0-9]+[a-zA-Z]*', ' ', text) # remove phone model, e.g. n9005\n",
    "\n",
    "\t# for tweets\n",
    "text = re.sub('[@]\\w+', '', text) # remove @mentions\n",
    "\n",
    "text = re.sub(r'(?:(?:https?|ftp):\\/\\/|www\\.)[A-Z-a-z0-9+&@#\\/%?=~_|!:,.;]*[A-Z-a-z0-9+&@#\\/%=~_|]', ' ', text) # remove URLs\n",
    "text = re.sub(r'[0-9]*', '', text) # remove numbers\n",
    "text = re.sub(r'\\b([0-9]*[apAP][mM])\\b', '', text) # remove 1am, 03pm, etc\n",
    "text = re.sub('[\\W]+', ' ', text)\n",
    "\n",
    "text = unicodedata.normalize('NFD', text).encode('ascii', 'ignore')\n",
    "text = text.decode(\"utf-8\") \n",
    "# print (type(text))\n",
    "print (text)\n",
    "# words = [w.lower() for w in text.split() if len(w) > 1]\n",
    "# print (' '.join(words))\n",
    "\n",
    "words = [w.lower() for w in text.split() if len(w) > 1]\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "words = [wnl.lemmatize(w) if len5w(w) > 1 else w for w in words]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "things = {\"fruits\":[\"apple\", \"pear\"], \"vehicles\":[\"car\",\"bus\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'pear']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "things[\"fruits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6]]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists = []\n",
    "list1 = [1,2,3]\n",
    "list2 = [4,5,6]\n",
    "lists.append(list1)\n",
    "lists.append(list2)\n",
    "lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# a = None\n",
    "if 1 < 2:\n",
    "    a = 3\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import operator\n",
    "dict1 = {\"car\":\"2\"}\n",
    "dict2 = {\"dog\":\"3\"}\n",
    "list1 = [dict1, dict2]\n",
    "\n",
    "dict3 = {\"apple\":\"hi\"}\n",
    "dict4 = {\"boy\":\"bye\"}\n",
    "list2 = [dict3, dict4]\n",
    "\n",
    "\n",
    "fset = []\n",
    "\n",
    "[x.update(y) for x, y in zip(list1, list2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A1', 'B2', 'C3']"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List1 = ['A', 'B', 'C']\n",
    "List2 = ['1', '2', '3']\n",
    "list(map(lambda a, b: a + b, List1, List2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict3 = dict1.update(dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-244-a9020180282b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print (dict3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 4}"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = {'a': 1, 'b': 4} \n",
    "d2 = {'b': 6, 'c': 3}\n",
    "d3 = {}\n",
    "d3.update(d1)\n",
    "d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    if (i +1) == 2:\n",
    "        break\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge_features(feature_lists):\n",
    "\n",
    "    if not feature_lists or len(feature_lists) < 1:\n",
    "        raise Exception('No list of features to merge.')\n",
    "\n",
    "    if len(feature_lists) == 1:\n",
    "        return feature_lists\n",
    "\n",
    "    comb_feature_list = feature_lists[0]\n",
    "    for i in range(len(feature_lists)):\n",
    "        # to prevent index out of range\n",
    "        if (i + 1) == len(feature_lists):\n",
    "            break\n",
    "        next_feature_list = feature_lists[i + 1]\n",
    "        for x, y in zip(comb_feature_list, next_feature_list):\n",
    "            x.update(y)\n",
    "        i += 1\n",
    "\n",
    "    return comb_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-268-da6b768ae812>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-268-da6b768ae812>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    list1 =\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "list1 ={\"style_pos_help\":2.123, \"style_pos_kind\":3.123}\n",
    "list2 ={\"style_neg_kill\":2.123, \"style_neg_beat\":2.123}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('blue', 3)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "list1 = ['red', 'blue', 'red', 'green', 'blue', 'blue']\n",
    "\n",
    "Counter(list1).most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "text = \"i am writing a short example for fun. singapore government is the best of the best and is so caring\"\n",
    "v2 = \"caring best fun\".split()\n",
    "text = re.sub(r'[0-9!@#$%^&*+=()\\[\\]\\?<>/\\\\-_\\.,;:\"\\']', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fun', 'best', 'best', 'caring']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = [i for i in text.split() if i in v2]\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['caring', 'best', 'best', 'fun']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = []\n",
    "for vi in v2:\n",
    "    for ti in text.split():\n",
    "        if vi in ti:\n",
    "            m.append(vi)\n",
    "            \n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'am',\n",
       " 'writing',\n",
       " 'a',\n",
       " 'short',\n",
       " 'example',\n",
       " 'for',\n",
       " 'fun.',\n",
       " 'singapore',\n",
       " 'government',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'of',\n",
       " 'the',\n",
       " 'best',\n",
       " 'and',\n",
       " 'is',\n",
       " 'so',\n",
       " 'caring']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hibye'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"hi\"\n",
    "b = \"bye\"\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: fruit v: ['apple', 'pear', 'orange']\n",
      "k: animal v: ['cat', 'dog', 'bird']\n"
     ]
    }
   ],
   "source": [
    "dic = {\"fruit\":[\"apple\", \"pear\", \"orange\"],\"animal\":[\"cat\",\"dog\",\"bird\"]}\n",
    "for k, v in dic.items():\n",
    "    print (\"k: \" + k + \" v: \" + str(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#SG PM l non stop @leehsienloong taken off stage after appearing to briefly falter during his address at #ndrsg. CNA: \"His condition is not serious\" #SG PM @leehsienloong expected to resume his #ndrsg address at   .  PM local time.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = '#SG PM leee non-stop @leehsienloong taken off stage after appearing to briefly falter during his address at #ndrsg. CNA: \"His condition is not serious\" #SG PM @leehsienloong expected to resume his #ndrsg address at 10.40PM local time.'\n",
    "# texts = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \", texts).split())\n",
    "texts = re.sub('[0-9]', ' ', texts)\n",
    "texts = texts.replace('_', ' ').replace('-', ' ')\n",
    "texts = re.sub(r'((\\w)\\2{2,})', '', texts)\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bye': 11, 'random': 15}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "word_feat = {\"hello\":10,\"bye\":11,\"random\":15}\n",
    "\n",
    "word_feat = sorted(word_feat.items(), key=operator.itemgetter(1), reverse=True)\n",
    "word_feat = dict(word_feat[:2])\n",
    "word_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'byeo': 11, 'helloo': 10, 'randomo': 15}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_feat = {\"hello\":10,\"bye\":11,\"random\":15}\n",
    "word_feat3 = {}\n",
    "for k,v in word_feat.items():\n",
    "    if k + 'o' not in word_feat:\n",
    "        word_feat3[k + 'o'] = v\n",
    "word_feat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Hello, world.\n",
      "Natural Language Processing in 10 lines of code.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Hello, world. Natural Language Processing in 10 lines of code.')\n",
    "# Get first token of the processed document\n",
    "token = doc[0]\n",
    "print(token)\n",
    "\n",
    "# Print sentences (one sentence per line)\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello - INTJ\n",
      ", - PUNCT\n",
      "world - NOUN\n",
      ". - PUNCT\n",
      "Natural - PROPN\n",
      "Language - PROPN\n",
      "Processing - PROPN\n",
      "in - ADP\n",
      "10 - NUM\n",
      "lines - NOUN\n",
      "of - ADP\n",
      "code - NOUN\n",
      ". - PUNCT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For each token, print corresponding part of speech tag\n",
    "for token in doc:\n",
    "    print('{} - {}'.format(token, token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello --> []\n",
      ", --> [,, Hello]\n",
      "world --> [world, Hello]\n",
      ". --> [., Hello]\n",
      "Natural --> [Natural, Processing]\n",
      "Language --> [Language, Processing]\n",
      "Processing --> []\n",
      "in --> [in, Processing]\n",
      "10 --> [10, lines, lines, in, in, Processing]\n",
      "lines --> [lines, in, in, Processing]\n",
      "of --> [of, lines, lines, in, in, Processing]\n",
      "code --> [code, of, of, lines, lines, in, in, Processing]\n",
      ". --> [., Processing]\n",
      "\n",
      ",-punct-> Hello-ROOT\n",
      "world-npadvmod-> Hello-ROOT\n",
      ".-punct-> Hello-ROOT\n",
      "Natural-compound-> Processing-ROOT\n",
      "Language-compound-> Processing-ROOT\n",
      "\n",
      "in-prep-> Processing-ROOT\n",
      "10-nummod-> lines-pobj-> lines-pobj-> in-prep-> in-prep-> Processing-ROOT\n",
      "lines-pobj-> in-prep-> in-prep-> Processing-ROOT\n",
      "of-prep-> lines-pobj-> lines-pobj-> in-prep-> in-prep-> Processing-ROOT\n",
      "code-pobj-> of-prep-> of-prep-> lines-pobj-> lines-pobj-> in-prep-> in-prep-> Processing-ROOT\n",
      ".-punct-> Processing-ROOT\n"
     ]
    }
   ],
   "source": [
    "def tokens_to_root(token):\n",
    "    \"\"\"\n",
    "    Walk up the syntactic tree, collecting tokens to the root of the given `token`.\n",
    "    :param token: Spacy token\n",
    "    :return: list of Spacy tokens\n",
    "    \"\"\"\n",
    "    tokens_to_r = []\n",
    "    while token.head is not token:\n",
    "        tokens_to_r.append(token)\n",
    "        token = token.head\n",
    "        tokens_to_r.append(token)\n",
    "\n",
    "    return tokens_to_r\n",
    "\n",
    "# For every token in document, print it's tokens to the root\n",
    "for token in doc:\n",
    "    print('{} --> {}'.format(token, tokens_to_root(token)))\n",
    "\n",
    "# Print dependency labels of the tokens\n",
    "for token in doc:\n",
    "    print('-> '.join(['{}-{}'.format(dependent_token, dependent_token.dep_) for dependent_token in tokens_to_root(token)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 166-170: truncated \\uXXXX escape (<ipython-input-42-0b2f2612478d>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-42-0b2f2612478d>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    text = 'To: Reach  PM Lee at 3pm\\n\\u6211\\u8981\\u5411\\u9648\\u632F\\u58F0\\u5927\\u90E8\\u957F\\u53D1\\u51FA\\u6700\\u4E25\\u5389\\u7684\\u8B66\\u544A, \\u8BF7\\u4E0D\\u8981\\u5728\\u4E00\\u77AC\\u87E wdw'\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 166-170: truncated \\uXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import codecs\n",
    "text = 'To: Reach  PM Lee at 3pm\\n\\u6211\\u8981\\u5411\\u9648\\u632F\\u58F0\\u5927\\u90E8\\u957F\\u53D1\\u51FA\\u6700\\u4E25\\u5389\\u7684\\u8B66\\u544A, \\u8BF7\\u4E0D\\u8981\\u5728\\u4E00\\u77AC\\u87E wdw'\n",
    "text = unicodedata.normalize('NFD', text).encode('ascii', 'ignore')\n",
    "text = text.decode(\"utf-8\") \n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
